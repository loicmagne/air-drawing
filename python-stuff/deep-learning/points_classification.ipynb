{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNs are used over point sequence to predict whether the user wanted to have the pencil up or pencil down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import cv2\n",
    "from os import listdir\n",
    "from contextlib import ExitStack\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0+cu102\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrawingsDS(torch.utils.data.Dataset):\n",
    "    def __init__(self, folder=\"../../data/processed_labeled/\"):\n",
    "        self.folder = folder\n",
    "        self.ds = []\n",
    "        self.n = 6\n",
    "        for f in listdir(self.folder):\n",
    "            self.ds.append(self.load_file(f))\n",
    "        \n",
    "        self.compute_mean()\n",
    "        self.compute_std()\n",
    "        \n",
    "        for f in self.ds:\n",
    "            f['input'] = (f['input'] - self.mean)/self.std\n",
    "        \n",
    "    def compute_mean(self):\n",
    "        self.mean = np.zeros(self.n)\n",
    "        tot = 0\n",
    "        self.y_mean = 0\n",
    "        for f in self.ds:\n",
    "            x = f['input']\n",
    "            self.mean += np.sum(x,axis=0)\n",
    "            self.y_mean += np.sum(f['output'])\n",
    "            tot += x.shape[0]\n",
    "        self.mean /= tot\n",
    "        self.y_mean /= tot\n",
    "        \n",
    "        \n",
    "    def compute_std(self):\n",
    "        variance = np.zeros(self.n)\n",
    "        tot = 0\n",
    "        for f in self.ds:\n",
    "            x = f['input'] - self.mean\n",
    "            x = np.square(x)\n",
    "            variance += np.sum(x,axis=0)\n",
    "            tot += x.shape[0]\n",
    "        variance /= tot\n",
    "        self.std = np.sqrt(variance)\n",
    "        \n",
    "    def load_file(self,f):\n",
    "        df = pd.read_csv(self.folder+f,index_col=0)\n",
    "        raw_pos = df[['x','y']].to_numpy().astype(np.int)\n",
    "        raw_inputs = df[['vx','vy','v','ax','ay','a']].to_numpy().astype(np.double).copy()\n",
    "        inputs = df[['vx','vy','v','ax','ay','a']].to_numpy().astype(np.double).copy()\n",
    "        output = df[['label']].to_numpy().astype(np.double)\n",
    "        distance = df[['dist']].to_numpy().astype(np.double)\n",
    "        return {\n",
    "            'raw_pos' : raw_pos,\n",
    "            'raw_input' : raw_inputs,\n",
    "            'input' : inputs,\n",
    "            'output' : output,\n",
    "            'name': f,\n",
    "            'dist': distance\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.ds[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.24121178  0.24171754  9.58346554  0.01237983  0.09380086  6.99433956]\n",
      "0.56051923751608\n",
      "[12.08068013 10.86206077 13.12253769 11.87022658  9.88225856 13.77132816]\n",
      "(262, 6)\n",
      "(262, 1)\n",
      "n_train : 216, n_test : 24\n"
     ]
    }
   ],
   "source": [
    "dataset = DrawingsDS()\n",
    "print(dataset.mean)\n",
    "print(dataset.y_mean)\n",
    "print(dataset.std)\n",
    "print(dataset[0]['input'].shape)\n",
    "print(dataset[0]['output'].shape)\n",
    "n = len(dataset)\n",
    "n_test = n//10\n",
    "n_train = n - n_test\n",
    "print(f'n_train : {n_train}, n_test : {n_test}')\n",
    "train_set, test_set = torch.utils.data.random_split(dataset,(n_train,n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(sample,pred):\n",
    "    sample_output = np.squeeze(pred)\n",
    "    pts = sample['raw_pos'][sample_output == True]\n",
    "\n",
    "    img = np.zeros((720,1280), dtype=np.uint8)\n",
    "    img[pts.T[1],pts.T[0]]=255\n",
    "    img = cv2.flip(img, 1)\n",
    "\n",
    "    cv2.imshow('frame', img)\n",
    "    key = cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnBlock(torch.nn.Module):\n",
    "    def __init__(self,in_features,num_heads,out_features): \n",
    "        super(AttnBlock, self).__init__()\n",
    "        self.attn = torch.nn.MultiheadAttention(\n",
    "            embed_dim = in_features,\n",
    "            num_heads = num_heads,\n",
    "            batch_first = True\n",
    "        )\n",
    "        self.fwd = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=in_features,out_features=out_features),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    def forward(self,x):\n",
    "        return self.relu(self.fwd(self.attn(x,x,x)[0]))\n",
    "    \n",
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self,in_features,out_features,kernel_size=7):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = torch.nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=kernel_size//2\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        output = torch.transpose(x,1,2)\n",
    "        output = self.conv(output)\n",
    "        output = torch.transpose(output,1,2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConvModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size=6,\n",
    "        output_size=1,\n",
    "        conv_seq=[16,32,64,128,64,32,16]\n",
    "    ):\n",
    "        super(FullyConvModel, self).__init__()\n",
    "    \n",
    "        layers = [ConvBlock(input_size,conv_seq[0])]\n",
    "        for k in range(len(conv_seq)-1):\n",
    "            layers.append(ConvBlock(conv_seq[k],conv_seq[k+1]))\n",
    "        self.layers = torch.nn.Sequential(*layers)\n",
    "        self.fc1 = torch.nn.Linear(in_features=conv_seq[-1],out_features=conv_seq[-1]//2)\n",
    "        self.fc2 = torch.nn.Linear(in_features=conv_seq[-1]//2,out_features=conv_seq[-1]//2)\n",
    "        self.fc3 = torch.nn.Linear(in_features=conv_seq[-1]//2,out_features=output_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        output = self.layers(x)\n",
    "        output = self.fc3(self.relu(self.fc2(self.relu(self.fc1(output)))))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRecurrentModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size=6,\n",
    "        output_size=1,\n",
    "        hidden_size_in=64,\n",
    "        hidden_size_out=32,\n",
    "        num_layers=2,\n",
    "        model=torch.nn.GRU,\n",
    "        dropout=0.2,\n",
    "        bidirectional=True\n",
    "    ):\n",
    "        super(ConvRecurrentModel, self).__init__()\n",
    "        self.rnn = model(\n",
    "            input_size = hidden_size_in,\n",
    "            hidden_size = hidden_size_out,\n",
    "            num_layers = num_layers,\n",
    "            dropout = dropout,\n",
    "            bidirectional = bidirectional\n",
    "        )\n",
    "        self.before = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=input_size,out_channels=hidden_size_in//2,kernel_size=5,padding=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv1d(in_channels=hidden_size_in//2,out_channels=hidden_size_in//2,kernel_size=5,padding=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv1d(in_channels=hidden_size_in//2,out_channels=hidden_size_in,kernel_size=5,padding=2)\n",
    "        )\n",
    "        self.after = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=2*hidden_size_out,out_channels=hidden_size_out,kernel_size=5,padding=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv1d(in_channels=hidden_size_out,out_channels=hidden_size_out,kernel_size=5,padding=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv1d(in_channels=hidden_size_out,out_channels=hidden_size_out//2,kernel_size=5,padding=2)\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(in_features=hidden_size_out//2,out_features=output_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = torch.transpose(x,1,2)\n",
    "        output = self.before(x)\n",
    "        \n",
    "        output = torch.transpose(output,2,1)\n",
    "        output = torch.transpose(output,0,1)\n",
    "        output, _ = self.rnn(output)\n",
    "        output = torch.transpose(output,0,1)\n",
    "        \n",
    "        output = torch.transpose(output,2,1)\n",
    "        output = self.after(output)\n",
    "        \n",
    "        output = torch.transpose(output,2,1)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The full model to be exported into ONNX. \n",
    "This model contains input normalization + sigmoid function at the end.\n",
    "\"\"\"\n",
    "class StandaloneModel(torch.nn.Module):\n",
    "    def __init__(self, trained_model, mean, std):\n",
    "        super(StandaloneModel,self).__init__()\n",
    "        self.model = trained_model\n",
    "        self.mean = torch.tensor(mean,dtype=torch.float32)\n",
    "        self.std = torch.tensor(std,dtype=torch.float32)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        output = torch.unsqueeze(x,0)\n",
    "        output = (output-self.mean)/self.std\n",
    "        output = self.model(output)\n",
    "        return torch.squeeze(self.sigmoid(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 456, 6])\n",
      "torch.Size([1, 456, 1])\n"
     ]
    }
   ],
   "source": [
    "model1 = ConvRecurrentModel(dataset.n).double()\n",
    "sample = torch.tensor(train_set[0]['input']).unsqueeze(0)\n",
    "print(sample.size())\n",
    "print(model1(sample).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 456, 6])\n",
      "torch.Size([1, 456, 1])\n"
     ]
    }
   ],
   "source": [
    "model2 = FullyConvModel(dataset.n).double()\n",
    "sample = torch.tensor(train_set[0]['input']).unsqueeze(0)\n",
    "print(sample.size())\n",
    "print(model2(sample).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([456, 6])\n",
      "torch.Size([456])\n"
     ]
    }
   ],
   "source": [
    "model3 = StandaloneModel(model1,dataset.mean,dataset.std)\n",
    "sample = torch.tensor(train_set[0]['raw_input'])\n",
    "print(sample.size())\n",
    "print(model3(sample).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred,y):\n",
    "    pred_np = pred.squeeze().detach().numpy()\n",
    "    y_np = y.squeeze().detach().numpy()\n",
    "    accuracy = accuracy_score(y_np,pred_np)\n",
    "    precision = precision_score(y_np,pred_np,zero_division=0)\n",
    "    recall = recall_score(y_np,pred_np,zero_division=0)\n",
    "    f1 = f1_score(y_np,pred_np,zero_division=0)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def save_model(model,name,acc):\n",
    "    acc = int(10000*acc)/100\n",
    "    f_name = f\"{int(name['MODEL_HIDDEN_SIZE_IN'])}_{int(name['MODEL_HIDDEN_SIZE_OUT'])}_{int(name['MODEL_NUM_LAYERS'])}_{acc}.pt\"\n",
    "    torch.save(model.state_dict(),\"../../models/\"+f_name)\n",
    "    \n",
    "\n",
    "def epoch(loader,optimizer,model,loss1,loss2,iteration_type='train',gradient_clipping=1.):\n",
    "    if iteration_type == 'train':\n",
    "        MODEL.train()\n",
    "    if iteration_type == 'test':\n",
    "        MODEL.eval()\n",
    "\n",
    "    with ExitStack() as stack:\n",
    "        if iteration_type == 'test':\n",
    "            gs = stack.enter_context(torch.no_grad())\n",
    "        \n",
    "        metrics = {\n",
    "            'loss': 0.,\n",
    "            'accuracy': 0.,\n",
    "            'precision': 0.,\n",
    "            'recall': 0.,\n",
    "            'f1': 0.\n",
    "        }\n",
    "        \n",
    "        n = len(loader)\n",
    "        for sample in loader:\n",
    "            # make predictions\n",
    "            x = sample['input']\n",
    "            y = sample['output'].squeeze()\n",
    "            dist = sample['dist'].squeeze()\n",
    "            augment = np.random.uniform(0.5,1.5) if iteration_type=='train' else 1.\n",
    "            pred = MODEL(augment*x).squeeze()\n",
    "            # compute losses\n",
    "            l = loss1(pred,y) + loss2(pred,y)\n",
    "            # apply backprop\n",
    "            if iteration_type == 'train':\n",
    "                OPTIMIZER.zero_grad()\n",
    "                l.backward()\n",
    "                '''torch.nn.utils.clip_grad_norm_(\n",
    "                    parameters = model.parameters(),\n",
    "                    max_norm = gradient_clipping\n",
    "                )'''\n",
    "                OPTIMIZER.step()\n",
    "                \n",
    "            acc, prec, rec, f1 = compute_metrics(torch.sigmoid(pred)>0.5,y)\n",
    "            metrics['loss'] += l.item()/n\n",
    "            metrics['accuracy'] += acc/n\n",
    "            metrics['precision'] += prec/n\n",
    "            metrics['recall'] += rec/n\n",
    "            metrics['f1'] += f1/n\n",
    "    return metrics\n",
    "\n",
    "class DiceLoss(torch.nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = torch.nn.functional.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: lmagne (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">ethereal-darkness-344</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/lmagne/r-drawing\" target=\"_blank\">https://wandb.ai/lmagne/r-drawing</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/lmagne/r-drawing/runs/1g4aamcp\" target=\"_blank\">https://wandb.ai/lmagne/r-drawing/runs/1g4aamcp</a><br/>\n",
       "                Run data is saved locally in <code>/home/loic/Documents/Prog/Projets/air-drawing/python-stuff/deep-learning/wandb/run-20210911_023113-1g4aamcp</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = {\n",
    "    \"EPOCHS\" : 1000,\n",
    "    \"BATCH_SIZE\" : 1,\n",
    "    \"LEARNING_RATE\" : 3e-4,\n",
    "    \"NUM_WORKERS\" : 2,\n",
    "    \"PIN_MEMORY\" : True,\n",
    "    \"MODEL_HIDDEN_SIZE_IN\" : 32,\n",
    "    \"MODEL_HIDDEN_SIZE_OUT\" : 16,\n",
    "    \"MODEL_NUM_LAYERS\" : 1,\n",
    "    \"WEIGHT_DECAY\" : 0.,\n",
    "    \"SCHEDULER_GAMMA\" : 0.1,\n",
    "    \"SEED\" : 179428,\n",
    "    \"DROPOUT\" : 0.2,\n",
    "    \"GRADIENT_CLIPPING\" : None,\n",
    "    \"BIDIRECTIONAL\" : True\n",
    "}\n",
    "log = True\n",
    "if log:\n",
    "    run = wandb.init(project=\"r-drawing\",config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_train : 216, n_test : 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loic/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/loic/.local/lib/python3.8/site-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|██████████| 1000/1000 [6:51:24<00:00, 24.68s/it] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 380651<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef52a64f6b0f416a9f8eb5a721be40e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/loic/Documents/Prog/Projets/air-drawing/python-stuff/deep-learning/wandb/run-20210911_023113-1g4aamcp/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/loic/Documents/Prog/Projets/air-drawing/python-stuff/deep-learning/wandb/run-20210911_023113-1g4aamcp/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss_train</td><td>0.01581</td></tr><tr><td>loss_test</td><td>1.55788</td></tr><tr><td>accuracy_train</td><td>0.99629</td></tr><tr><td>accuracy_test</td><td>0.90854</td></tr><tr><td>precision_train</td><td>0.99649</td></tr><tr><td>precision_test</td><td>0.93689</td></tr><tr><td>recall_train</td><td>0.99672</td></tr><tr><td>recall_test</td><td>0.90786</td></tr><tr><td>f1_train</td><td>0.9966</td></tr><tr><td>f1_test</td><td>0.92045</td></tr><tr><td>_runtime</td><td>24688</td></tr><tr><td>_timestamp</td><td>1631344961</td></tr><tr><td>_step</td><td>999</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss_train</td><td>█▅▄▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_test</td><td>▄▂▁▁▁▁▁▁▁▂▁▂▂▂▂▃▃▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>accuracy_train</td><td>▁▄▅▆▆▆▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>accuracy_test</td><td>▁▄▆▇▇▇▇██▇████▇▇████████████████████████</td></tr><tr><td>precision_train</td><td>▁▅▆▆▆▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>precision_test</td><td>▁▁▅▆▇▇▇▇██████▇▇▇██▇▇███████████████████</td></tr><tr><td>recall_train</td><td>▁▃▄▄▅▆▆▆▆▇▇▇▇▇▇▇████████████████████████</td></tr><tr><td>recall_test</td><td>▁▇▇▇▆▇▇██▆█▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>f1_train</td><td>▁▄▅▅▆▆▇▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>f1_test</td><td>▁▄▆▇▇▇▇██▇████▇▇████████████████████████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">ethereal-darkness-344</strong>: <a href=\"https://wandb.ai/lmagne/r-drawing/runs/1g4aamcp\" target=\"_blank\">https://wandb.ai/lmagne/r-drawing/runs/1g4aamcp</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(config[\"SEED\"])\n",
    "np.random.seed(config[\"SEED\"])\n",
    "\n",
    "dataset = DrawingsDS()\n",
    "n = len(dataset)\n",
    "n_test = n//10\n",
    "n_train = n - n_test\n",
    "print(f'n_train : {n_train}, n_test : {n_test}')\n",
    "train_set, test_set = torch.utils.data.random_split(dataset,(n_train,n_test))\n",
    "\n",
    "MODEL = ConvRecurrentModel(\n",
    "    input_size = dataset.n,\n",
    "    hidden_size_in = config[\"MODEL_HIDDEN_SIZE_IN\"],\n",
    "    hidden_size_out = config[\"MODEL_HIDDEN_SIZE_OUT\"],\n",
    "    num_layers = config[\"MODEL_NUM_LAYERS\"],\n",
    "    dropout = config[\"DROPOUT\"],\n",
    "    model=torch.nn.LSTM\n",
    ").double()\n",
    "\n",
    "LOSS1 = torch.nn.BCEWithLogitsLoss()\n",
    "LOSS2 = DiceLoss()\n",
    "\n",
    "OPTIMIZER = torch.optim.Adam(\n",
    "    MODEL.parameters(),\n",
    "    lr = config[\"LEARNING_RATE\"],\n",
    "    weight_decay = config[\"WEIGHT_DECAY\"]\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "OPTIMIZER = torch.optim.SGD(\n",
    "    MODEL.parameters(),\n",
    "    lr = config[\"LEARNING_RATE\"],\n",
    "    momentum = 0.9,\n",
    "    nesterov = True\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "SCHEDULER = torch.optim.lr_scheduler.StepLR(\n",
    "    OPTIMIZER,\n",
    "    step_size = 500,\n",
    "    gamma = config[\"SCHEDULER_GAMMA\"]\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size = config[\"BATCH_SIZE\"],\n",
    "    num_workers = config[\"NUM_WORKERS\"],\n",
    "    pin_memory = config[\"PIN_MEMORY\"],\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size = config[\"BATCH_SIZE\"],\n",
    "    num_workers = config[\"NUM_WORKERS\"],\n",
    "    pin_memory = config[\"PIN_MEMORY\"],\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "if log:\n",
    "    wandb.watch(MODEL)\n",
    "    \n",
    "best_so_far = 0.\n",
    "for k in tqdm(range(config[\"EPOCHS\"])):\n",
    "    train_metrics = epoch(train_loader,OPTIMIZER,MODEL,LOSS1,LOSS2,'train',config[\"GRADIENT_CLIPPING\"])\n",
    "    test_metrics = epoch(test_loader,OPTIMIZER,MODEL,LOSS1,LOSS2,'test')\n",
    "    if log:\n",
    "        wandb.log({\n",
    "            \"loss_train\" : train_metrics[\"loss\"],\n",
    "            \"loss_test\" : test_metrics[\"loss\"],\n",
    "            \"accuracy_train\" : train_metrics[\"accuracy\"],\n",
    "            \"accuracy_test\" : test_metrics[\"accuracy\"],\n",
    "            \"precision_train\" : train_metrics[\"precision\"],\n",
    "            \"precision_test\" : test_metrics[\"precision\"],\n",
    "            \"recall_train\" : train_metrics[\"recall\"],\n",
    "            \"recall_test\" : test_metrics[\"recall\"],\n",
    "            \"f1_train\" : train_metrics[\"f1\"],\n",
    "            \"f1_test\" : test_metrics[\"f1\"]\n",
    "        })\n",
    "    if test_metrics['accuracy'] > best_so_far:\n",
    "        save_model(MODEL,config,test_metrics['accuracy'])\n",
    "        best_so_far = test_metrics['accuracy']\n",
    "    SCHEDULER.step()\n",
    "\n",
    "if log:\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3_sample.csv\n",
      "1_flower.csv\n",
      "1_issouent.csv\n",
      "4_airplane.csv\n",
      "4_crayon.csv\n",
      "3_cat.csv\n",
      "1_lantern.csv\n",
      "4_leagueoflegends.csv\n",
      "3_magicien.csv\n",
      "1_prenom.csv\n"
     ]
    }
   ],
   "source": [
    "for k in range(10):\n",
    "    sample = test_set[k]\n",
    "    print(sample['name'])\n",
    "    x = torch.tensor(sample['input']).unsqueeze(0)\n",
    "    pred = (torch.sigmoid(MODEL(x)) > 0.5).detach().numpy()\n",
    "    visualize(sample,pred)\n",
    "    visualize(sample,sample['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../models/32_16_1_83.85.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7e6f4f92203b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0msafety_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-7e6f4f92203b>\u001b[0m in \u001b[0;36msafety_check\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     )\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"../../models/32_16_1_83.85.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mexportable_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandaloneModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../models/32_16_1_83.85.pt'"
     ]
    }
   ],
   "source": [
    "def safety_check():\n",
    "    MODEL = ConvRecurrentModel(\n",
    "        input_size = dataset.n,\n",
    "        hidden_size_in = 32,\n",
    "        hidden_size_out = 16,\n",
    "        num_layers = 1,\n",
    "        dropout = 0.,\n",
    "        model=torch.nn.LSTM\n",
    "    )\n",
    "    MODEL.load_state_dict(torch.load(f\"../../models/32_16_1_83.85.pt\"))\n",
    "    MODEL.eval()\n",
    "    exportable_model = StandaloneModel(MODEL,dataset.mean,dataset.std)\n",
    "    exportable_model.eval()\n",
    "    sample = test_set[0]\n",
    "    x1 = torch.tensor(sample['input'],dtype=torch.float32).unsqueeze(0)\n",
    "    x2 = torch.tensor(sample['raw_input'],dtype=torch.float32)\n",
    "    y1 = torch.sigmoid(MODEL(x1)).squeeze()\n",
    "    y2 = exportable_model(x2)\n",
    "    assert np.all(np.isclose(y1.detach().numpy(),y2.detach().numpy()))\n",
    "    assert np.all(np.isclose(y2.detach().numpy(),y1.detach().numpy()))\n",
    "safety_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toONNX():\n",
    "    MODEL = ConvRecurrentModel(\n",
    "        input_size = dataset.n,\n",
    "        hidden_size_in = 32,\n",
    "        hidden_size_out = 16,\n",
    "        num_layers = 1,\n",
    "        dropout = 0.,\n",
    "        model=torch.nn.LSTM\n",
    "    )\n",
    "    MODEL.load_state_dict(torch.load(f\"../../models/32_16_1_91.47.pt\"))\n",
    "    MODEL.eval()\n",
    "    exportable_model = StandaloneModel(MODEL,dataset.mean,dataset.std)\n",
    "    exportable_model.eval()\n",
    "    x = torch.randn(500, 6, requires_grad=True,dtype=torch.float)\n",
    "    y = exportable_model(x)\n",
    "    torch.onnx.export(exportable_model,               # model being run\n",
    "                      x,                         # model input (or a tuple for multiple inputs)\n",
    "                      f\"../../models/lstm_X_91_47.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                      input_names = ['input'],   # the model's input names\n",
    "                      output_names = ['output'], # the model's output names\n",
    "                      dynamic_axes={'input' : {0 : 'seq_len'},    # variable length axes\n",
    "                                    'output' : {0 : 'seq_len'}},\n",
    "                      verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input : Float(*, 6, strides=[6, 1], requires_grad=1, device=cpu),\n",
      "      %model.before.0.weight : Float(16, 6, 5, strides=[30, 5, 1], requires_grad=1, device=cpu),\n",
      "      %model.before.0.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %model.before.2.weight : Float(16, 16, 5, strides=[80, 5, 1], requires_grad=1, device=cpu),\n",
      "      %model.before.2.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %model.before.4.weight : Float(32, 16, 5, strides=[80, 5, 1], requires_grad=1, device=cpu),\n",
      "      %model.before.4.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %model.after.0.weight : Float(16, 32, 5, strides=[160, 5, 1], requires_grad=1, device=cpu),\n",
      "      %model.after.0.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %model.after.2.weight : Float(16, 16, 5, strides=[80, 5, 1], requires_grad=1, device=cpu),\n",
      "      %model.after.2.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %model.after.4.weight : Float(8, 16, 5, strides=[80, 5, 1], requires_grad=1, device=cpu),\n",
      "      %model.after.4.bias : Float(8, strides=[1], requires_grad=1, device=cpu),\n",
      "      %model.fc.bias : Float(1, strides=[1], requires_grad=1, device=cpu),\n",
      "      %114 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
      "      %115 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
      "      %116 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
      "      %117 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
      "      %158 : Float(2, 128, strides=[128, 1], requires_grad=0, device=cpu),\n",
      "      %159 : Float(2, 64, 32, strides=[2048, 32, 1], requires_grad=0, device=cpu),\n",
      "      %160 : Float(2, 64, 16, strides=[1024, 16, 1], requires_grad=0, device=cpu),\n",
      "      %161 : Float(8, 1, strides=[1, 8], requires_grad=0, device=cpu)):\n",
      "  %23 : Float(1, *, 6, strides=[3000, 6, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze[axes=[0]](%input) # <ipython-input-9-2989dca95cab>:14:0\n",
      "  %24 : Float(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=-0.2412  0.2417  9.5835  0.0124  0.0938  6.9943 [ CPUFloatType{6} ]]()\n",
      "  %25 : Float(1, *, 6, strides=[3000, 6, 1], requires_grad=1, device=cpu) = onnx::Sub(%23, %24) # <ipython-input-9-2989dca95cab>:15:0\n",
      "  %26 : Float(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 12.0807  10.8621  13.1225  11.8702   9.8823  13.7713 [ CPUFloatType{6} ]]()\n",
      "  %27 : Float(1, *, 6, strides=[3000, 6, 1], requires_grad=1, device=cpu) = onnx::Div(%25, %26) # <ipython-input-9-2989dca95cab>:15:0\n",
      "  %28 : Float(1, 6, *, strides=[3000, 1, 6], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1]](%27) # <ipython-input-8-a2387df70ed7>:38:0\n",
      "  %29 : Float(1, 16, *, strides=[8000, 500, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1]](%28, %model.before.0.weight, %model.before.0.bias) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:294:0\n",
      "  %30 : Float(1, 16, *, strides=[8000, 500, 1], requires_grad=1, device=cpu) = onnx::Relu(%29) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/functional.py:1298:0\n",
      "  %31 : Float(1, 16, *, strides=[8000, 500, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1]](%30, %model.before.2.weight, %model.before.2.bias) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:294:0\n",
      "  %32 : Float(1, 16, *, strides=[8000, 500, 1], requires_grad=1, device=cpu) = onnx::Relu(%31) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/functional.py:1298:0\n",
      "  %33 : Float(1, 32, *, strides=[16000, 500, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1]](%32, %model.before.4.weight, %model.before.4.bias) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:294:0\n",
      "  %34 : Float(*, 1, 32, strides=[1, 16000, 500], requires_grad=1, device=cpu) = onnx::Transpose[perm=[2, 0, 1]](%33) # <ipython-input-8-a2387df70ed7>:42:0\n",
      "  %35 : Long(3, strides=[1], device=cpu) = onnx::Shape(%34)\n",
      "  %36 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "  %37 : Long(device=cpu) = onnx::Gather[axis=0](%35, %36) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:658:0\n",
      "  %41 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%37)\n",
      "  %43 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%114, %41, %115)\n",
      "  %44 : Float(*, *, *, strides=[16, 16, 1], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0}](%43) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:665:0\n",
      "  %48 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%37)\n",
      "  %50 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%116, %48, %117)\n",
      "  %51 : Float(*, *, *, strides=[16, 16, 1], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0}](%50) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:668:0\n",
      "  %52 : Tensor? = prim::Constant()\n",
      "  %96 : Float(*, 2, 1, 16, device=cpu), %97 : Float(2, 1, 16, strides=[16, 16, 1], requires_grad=1, device=cpu), %98 : Float(2, 1, 16, strides=[16, 16, 1], requires_grad=1, device=cpu) = onnx::LSTM[direction=\"bidirectional\", hidden_size=16](%34, %159, %160, %158, %52, %44, %51) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:679:0\n",
      "  %99 : Float(*, 1, 2, 16, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%96)\n",
      "  %100 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 0  0 -1 [ CPULongType{3} ]]()\n",
      "  %101 : Float(*, 1, 32, strides=[32, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape(%99, %100) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:679:0\n",
      "  %102 : Float(1, 32, *, strides=[32, 1, 32], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 2, 0]](%101) # <ipython-input-8-a2387df70ed7>:46:0\n",
      "  %103 : Float(1, 16, *, strides=[8000, 500, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1]](%102, %model.after.0.weight, %model.after.0.bias) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:294:0\n",
      "  %104 : Float(1, 16, *, strides=[8000, 500, 1], requires_grad=1, device=cpu) = onnx::Relu(%103) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/functional.py:1298:0\n",
      "  %105 : Float(1, 16, *, strides=[8000, 500, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1]](%104, %model.after.2.weight, %model.after.2.bias) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:294:0\n",
      "  %106 : Float(1, 16, *, strides=[8000, 500, 1], requires_grad=1, device=cpu) = onnx::Relu(%105) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/functional.py:1298:0\n",
      "  %107 : Float(1, 8, *, strides=[4000, 500, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1]](%106, %model.after.4.weight, %model.after.4.bias) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:294:0\n",
      "  %108 : Float(1, *, 8, strides=[4000, 1, 500], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1]](%107) # <ipython-input-8-a2387df70ed7>:49:0\n",
      "  %110 : Float(1, *, 1, device=cpu) = onnx::MatMul(%108, %161)\n",
      "  %111 : Float(1, *, 1, strides=[500, 1, 1], requires_grad=1, device=cpu) = onnx::Add(%model.fc.bias, %110) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/functional.py:1847:0\n",
      "  %112 : Float(1, *, 1, strides=[500, 1, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%111) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py:299:0\n",
      "  %output : Float(500, strides=[1], requires_grad=1, device=cpu) = onnx::Squeeze(%112) # <ipython-input-9-2989dca95cab>:17:0\n",
      "  return (%output)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loic/.local/lib/python3.8/site-packages/torch/onnx/symbolic_opset9.py:2095: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\"Exporting a model to ONNX with a batch_size other than 1, \" +\n"
     ]
    }
   ],
   "source": [
    "toONNX()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
